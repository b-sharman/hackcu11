{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data scraping from XML file of bills\n",
    "# folder_path = './all_bills'\n",
    "# json_folder = './json'\n",
    "\n",
    "# bill_data = []\n",
    "\n",
    "# # counter = 0\n",
    "\n",
    "# def parse_bill(xml_file):\n",
    "#     parsed_data = {}\n",
    "\n",
    "#     try:\n",
    "#         tree = ET.parse(xml_file)\n",
    "#         root = tree.getroot()\n",
    "\n",
    "#         bill = root.find('bill')\n",
    "\n",
    "#         if bill is not None:\n",
    "#             parsed_data['number'] = bill.find('number').text if bill.find('number') is not None else None\n",
    "#             parsed_data['title'] = bill.find('title').text if bill.find('title') is not None else None\n",
    "#             parsed_data['introducedDate'] = bill.find('introducedDate').text if bill.find('introducedDate') is not None else None\n",
    "#             parsed_data['updateDate'] = bill.find('updateDate').text if bill.find('updateDate') is not None else None\n",
    "#             parsed_data['originChamber'] = bill.find('originChamber').text if bill.find('originChamber') is not None else None\n",
    "#             parsed_data['type'] = bill.find('type').text if bill.find('type') is not None else None\n",
    "#             parsed_data['congress'] = bill.find('congress').text if bill.find('congress') is not None else None\n",
    "\n",
    "#             actions = bill.find('actions')\n",
    "\n",
    "#             for item in actions.findall('item'):\n",
    "#                 parsed_data['actionCode'] = item.find('actionCode').text if item.find('actionCode') is not None else None   \n",
    "#                 break\n",
    "            \n",
    "#             if actions is not None:\n",
    "#                 first_item = actions.find('item')\n",
    "#                 if first_item is not None:\n",
    "#                     text = first_item.find('text').text if first_item.find('text') is not None else None\n",
    "#                     parsed_data['lastResult'] = text\n",
    "#                 else:\n",
    "#                     print(f\"No 'item' element found in {xml_file}\")\n",
    "#         else:\n",
    "#             print(f\"No 'bill' element found in {xml_file}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {xml_file}\")\n",
    "    \n",
    "#     return parsed_data\n",
    "\n",
    "# for file in os.listdir(folder_path):\n",
    "#     if file.endswith('.xml'):\n",
    "#         file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "#         bill_data.append(parse_bill(file_path))\n",
    "\n",
    "#         # counter += 1\n",
    "\n",
    "#         # if counter >= 5:\n",
    "#         #     break\n",
    "\n",
    "# df = pd.DataFrame(bill_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('smaller_set.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actionCode'].fillna(0, inplace=True)\n",
    "df = df.dropna()\n",
    "df['actionCode'] = df['actionCode'].astype(str)\n",
    "df['final'] = df['actionCode'].apply(lambda x: x in ['E30000', 'E40000', '36000'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['introducedDate'] = pd.to_datetime(df['introducedDate'])\n",
    "df['updateDate'] = pd.to_datetime(df['updateDate'])\n",
    "df['updateDate'] = df['updateDate'].dt.date\n",
    "df['introducedDate'] = df['introducedDate'].dt.date\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['updateDate'] = pd.to_datetime(df['updateDate'])\n",
    "df['introducedDate'] = pd.to_datetime(df['introducedDate'])\n",
    "\n",
    "df['duration'] = (df['updateDate'] - df['introducedDate']).dt.days\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final'] = df['final'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('filtered_bills.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['type', 'originChamber'])\n",
    "df = df_encoded\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('filtered_bills.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final'] = df['final'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = df.select_dtypes(include='bool').columns\n",
    "df[bool_columns] = df[bool_columns].astype(int)\n",
    "df['introducedDate'] = df['introducedDate'].astype(str)\n",
    "df['updateDate'] = df['updateDate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling data\n",
    "X = df.drop(columns=['title', 'introducedDate', 'updateDate', 'actionCode', 'lastResult', 'updateTime', 'final'])\n",
    "y = df['final']\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X, y = smote.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression model tried first\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "# print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "# print(f\"RMSE: {root_mean_squared_error(y_test, y_pred)}\")\n",
    "# print(f\"R² Score: {r2_score(y_test, y_pred)}\")\n",
    "\n",
    "# print(f\"accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "# print(f\"precision score: {precision_score(y_test, y_pred)}\")\n",
    "# print(f\"recall score: {recall_score(y_test, y_pred)}\")\n",
    "# print(f\"f1 score: {f1_score(y_test, y_pred)}\")\n",
    "# print(f\"confusion matrix: {confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest model tried next for better accuracy\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "probabilities = model.predict_proba(X_test)\n",
    "pass_probabilities = probabilities[:, 1]\n",
    "\n",
    "for i, prob in enumerate(pass_probabilities):\n",
    "    print(f\"Probability of passing = {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting model for use with backend\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred)}\")\n",
    "\n",
    "print(f\"accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"precision score: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall score: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1 score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"confusion matrix: {confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using random forest to predict on fake data\n",
    "fake_data = {\n",
    "    'number': [101], \n",
    "    'congress': [118], \n",
    "    'duration': [45],  \n",
    "    'type_HCONRES': [1],  \n",
    "    'type_HJRES': [0],  \n",
    "    'type_HR': [0],      \n",
    "    'type_HRES': [0],    \n",
    "    'type_S': [0],       \n",
    "    'type_SCONRES': [0], \n",
    "    'type_SJRES': [0],   \n",
    "    'type_SRES': [0],     \n",
    "    'originChamber_House': [1],  \n",
    "    'originChamber_Senate': [0]  \n",
    "}\n",
    "\n",
    "fake_data_df = pd.DataFrame(fake_data)\n",
    "\n",
    "predicted_outcome = model.predict(fake_data_df)\n",
    "\n",
    "print(\"Will this bill pass?\")\n",
    "\n",
    "if predicted_outcome[0] == 1:\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
